{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f38357",
   "metadata": {},
   "source": [
    "# This file ingests the joined collection from MongoDB, parses out the joined column, formats the data, and exports a csv for use in the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe91392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67324c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb+srv://bootcamp_capstone:heart123@bootcamp.kzqan.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadcf229",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client[\"heart_db\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c786e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db[\"heart_joined\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48140bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_record = collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(one_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = collection.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b132781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row in all_records:\n",
    "    #print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run to create cursor\n",
    "all_records = collection.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45019761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make cursor a list\n",
    "list_cursor = list(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffa629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final dataframe\n",
    "df = pd.DataFrame(list_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0de21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop _id column\n",
    "clean_df = df.drop(['_id', 'joined'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breakout joined column\n",
    "s = df['joined'].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(list(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2fee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(['_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07022868",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(clean_df, new_df, on='id')\n",
    "final_df = final_df.drop(['id', '_id'], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3d29e2",
   "metadata": {},
   "source": [
    "## Export df for machine learning use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af61dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_df', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.io.sql as sqlio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if there are any null values\n",
    "for column in final_df.columns:\n",
    "    print(f\"Column {column} has {final_df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "heart_cat = final_df.dtypes[final_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "final_df[heart_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417086e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f31060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(final_df[heart_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(heart_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "final_df = final_df.merge(encode_df,left_index=True, right_index=True)\n",
    "final_df = final_df.drop(heart_cat,1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove loan status target from features data\n",
    "y = final_df.HeartDisease.values\n",
    "X = final_df.copy()\n",
    "X = X.drop(\"HeartDisease\", axis=1)\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.6, random_state=42, stratify=y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "   max_iter=200,\n",
    "   random_state=1)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b7781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6580c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b041d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': classifier.coef_[0]\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811bb2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487f75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
